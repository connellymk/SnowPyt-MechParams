{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1855c12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python bytecode cache disabled\n"
     ]
    }
   ],
   "source": [
    "# Disable Python bytecode cache to prevent stale .pyc files\n",
    "import sys\n",
    "import os\n",
    "sys.dont_write_bytecode = True\n",
    "os.environ['PYTHONDONTWRITEBYTECODE'] = '1'\n",
    "print(\"Python bytecode cache disabled\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837c4031",
   "metadata": {},
   "source": [
    "Setup: Disable Python Bytecode Cache\n",
    "\n",
    "This cell prevents Python from creating .pyc cache files that can cause stale code to be loaded even after source files are updated.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bededb57",
   "metadata": {},
   "source": [
    "# Snow Elastic Modulus Calculations - Bergfeld et al. (2023) Method\n",
    "\n",
    "This notebook demonstrates the application of the Bergfeld et al. (2023) elastic modulus parameterization to snowpit data. The Bergfeld method calculates elastic modulus from snow density using a power-law relationship optimized from Propagation Saw Test (PST) data.\n",
    "\n",
    "The analysis uses the local snowpyt_mechparams package and snowpylot for CAAML parsing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0310351f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44d98f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from uncertainties import ufloat\n",
    "import warnings\n",
    "\n",
    "\n",
    "# Add the src directory to the path to import snowpyt_mechparams\n",
    "sys.path.append('../src')\n",
    "from snowpilot_utils import convert_grain_form, parse_sample_pits\n",
    "from snowpyt_mechparams import density, elastic_modulus\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a001c4",
   "metadata": {},
   "source": [
    "Parse Snowpit Files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c14f4c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully parsed 50278 files\n",
      "Failed to parse 0 files\n"
     ]
    }
   ],
   "source": [
    "# Parse all snowpit files from the data folder\n",
    "all_pits = parse_sample_pits('data')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9553a70d",
   "metadata": {},
   "source": [
    "Apply Bergfeld parameterization using density and associated uncertainty from:\n",
    "1. Direct Measurement\n",
    "2. Kim_geldsetzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d736469",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect relevant data from each snowpit\n",
    "pit_info = []\n",
    "layer_info = []\n",
    "density_info = []  # New list for density observations\n",
    "\n",
    "for pit in all_pits:\n",
    "    pit_dict = {\n",
    "        'pit_id': pit.core_info.pit_id,\n",
    "        'layer_count': len(pit.snow_profile.layers),\n",
    "    }\n",
    "    pit_info.append(pit_dict)\n",
    "\n",
    "    for layer in pit.snow_profile.layers:\n",
    "        # Create base layer dictionary\n",
    "        layer_depth_top = layer.depth_top[0] if layer.depth_top else None\n",
    "        layer_thickness = layer.thickness[0] if layer.thickness else None\n",
    "        \n",
    "        layer_dict = {\n",
    "            'pit_id': pit.core_info.pit_id,\n",
    "            'hand_hardness': layer.hardness,\n",
    "            'depth_top': layer_depth_top,      # Add for merging (scalar)\n",
    "            'thickness': layer_thickness,      # Add for merging (scalar)\n",
    "        }\n",
    "\n",
    "        # Add kim_geldsetzer grain form conversion if grain form data exists\n",
    "        if layer.grain_form_primary:\n",
    "            layer_dict['kim_geldsetzer_grain_form'] = convert_grain_form(layer.grain_form_primary, 'kim_geldsetzer')\n",
    "            try: \n",
    "                # Calculate density using kim_geldsetzer method - only if we have valid inputs\n",
    "                if layer.hardness and layer_dict['kim_geldsetzer_grain_form']:\n",
    "                    density_ufloat = density.calculate_density( \n",
    "                        method='kim_geldsetzer',\n",
    "                        hand_hardness=layer.hardness,\n",
    "                        grain_form=layer_dict['kim_geldsetzer_grain_form']\n",
    "                    )\n",
    "                    layer_dict['density_kim_geldsetzer'] = density_ufloat.nominal_value\n",
    "                    layer_dict['density_kim_geldsetzer_uncertainty'] = density_ufloat.std_dev\n",
    "                else:\n",
    "                    layer_dict['density_kim_geldsetzer'] = None\n",
    "                    layer_dict['density_kim_geldsetzer_uncertainty'] = None\n",
    "            except Exception:\n",
    "                layer_dict['density_kim_geldsetzer'] = None\n",
    "                layer_dict['density_kim_geldsetzer_uncertainty'] = None\n",
    "        else:\n",
    "            layer_dict['kim_geldsetzer_grain_form'] = None\n",
    "            layer_dict['density_kim_geldsetzer'] = None\n",
    "            layer_dict['density_kim_geldsetzer_uncertainty'] = None\n",
    "\n",
    "        layer_info.append(layer_dict)\n",
    "\n",
    "    # Collect density observations separately\n",
    "    for density_obs in pit.snow_profile.density_profile:\n",
    "        # Extract scalar density value\n",
    "        density_value = density_obs.density\n",
    "        if hasattr(density_value, '__len__') and len(density_value) > 0:\n",
    "            density_value = density_value[0]  # Take first element if it's an array\n",
    "        if hasattr(density_value, 'nominal_value'):\n",
    "            density_value = density_value.nominal_value  # Extract nominal value if it's a ufloat\n",
    "        \n",
    "        obs_depth_top = density_obs.depth_top[0] if density_obs.depth_top else None\n",
    "        obs_thickness = density_obs.thickness[0] if density_obs.thickness else None\n",
    "        \n",
    "        density_dict = {\n",
    "            'pit_id': pit.core_info.pit_id,\n",
    "            'depth_top': obs_depth_top,\n",
    "            'thickness': obs_thickness,\n",
    "            'density_measured': float(density_value) if density_value is not None else None\n",
    "        }\n",
    "        density_info.append(density_dict)\n",
    "\n",
    "# Create dataframes\n",
    "pit_df = pd.DataFrame(pit_info)\n",
    "layer_df = pd.DataFrame(layer_info)\n",
    "density_df = pd.DataFrame(density_info)\n",
    "\n",
    "# Merge density_measured into layer_df using pandas merge (efficient matching)\n",
    "layer_df = layer_df.merge(\n",
    "    density_df[['pit_id', 'depth_top', 'thickness', 'density_measured']],\n",
    "    on=['pit_id', 'depth_top', 'thickness'],\n",
    "    how='left'\n",
    ").drop(columns=['depth_top', 'thickness'])  # Drop temporary columns after merge\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0adb0a42",
   "metadata": {},
   "source": [
    "Apply Bergfeld Elastic Modulus Parameterization\n",
    "\n",
    "Now we'll apply the Bergfeld et al. (2023) method to calculate elastic modulus for all layers that have density values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14ee1941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing kim_geldsetzer density method...\n",
      "Processing measured density method...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marykateconnelly/Desktop/F25/SnowPyt-MechParams/venv/lib/python3.13/site-packages/uncertainties/core.py:1024: UserWarning: Using UFloat objects with std_dev==0 may give unexpected results.\n",
      "  warn(\"Using UFloat objects with std_dev==0 may give unexpected results.\")\n",
      "/Users/marykateconnelly/Desktop/F25/SnowPyt-MechParams/venv/lib/python3.13/site-packages/uncertainties/core.py:1024: UserWarning: Using UFloat objects with std_dev==0 may give unexpected results.\n",
      "  warn(\"Using UFloat objects with std_dev==0 may give unexpected results.\")\n"
     ]
    }
   ],
   "source": [
    "# Apply Bergfeld Elastic Modulus Parameterization to both density methods\n",
    "\n",
    "# Initialize results storage\n",
    "results = {\n",
    "    'kim_geldsetzer': {\n",
    "        'elastic_modulus_values': [],\n",
    "        'successful_count': 0\n",
    "    },\n",
    "    'measured': {\n",
    "        'elastic_modulus_values': [],\n",
    "        'successful_count': 0\n",
    "    }\n",
    "}\n",
    "\n",
    "# Process kim_geldsetzer density method (with uncertainty)\n",
    "print(\"Processing kim_geldsetzer density method...\")\n",
    "for idx, row in layer_df.iterrows():\n",
    "    if pd.notna(row['density_kim_geldsetzer']) and pd.notna(row['density_kim_geldsetzer_uncertainty']):\n",
    "        # Create ufloat with density and uncertainty\n",
    "        density_ufloat = ufloat(row['density_kim_geldsetzer'], row['density_kim_geldsetzer_uncertainty'])\n",
    "        \n",
    "        # Calculate elastic modulus using Bergfeld method\n",
    "        try:\n",
    "            E_modulus = elastic_modulus.calculate_elastic_modulus(method='bergfeld', density=density_ufloat)\n",
    "            \n",
    "            # Check if result is valid (not NaN)\n",
    "            if not np.isnan(E_modulus.nominal_value):\n",
    "                results['kim_geldsetzer']['elastic_modulus_values'].append(E_modulus)\n",
    "                results['kim_geldsetzer']['successful_count'] += 1\n",
    "                \n",
    "                # Store results back in dataframe\n",
    "                layer_df.at[idx, 'elastic_modulus_bergfeld_kim_geldsetzer'] = E_modulus.nominal_value\n",
    "                layer_df.at[idx, 'elastic_modulus_bergfeld_kim_geldsetzer_uncertainty'] = E_modulus.std_dev\n",
    "                layer_df.at[idx, 'elastic_modulus_bergfeld_kim_geldsetzer_relative_uncertainty'] = E_modulus.std_dev / E_modulus.nominal_value\n",
    "            else:\n",
    "                layer_df.at[idx, 'elastic_modulus_bergfeld_kim_geldsetzer'] = np.nan\n",
    "                layer_df.at[idx, 'elastic_modulus_bergfeld_kim_geldsetzer_uncertainty'] = np.nan\n",
    "                layer_df.at[idx, 'elastic_modulus_bergfeld_kim_geldsetzer_relative_uncertainty'] = np.nan\n",
    "                \n",
    "        except Exception as e:\n",
    "            layer_df.at[idx, 'elastic_modulus_bergfeld_kim_geldsetzer'] = np.nan\n",
    "            layer_df.at[idx, 'elastic_modulus_bergfeld_kim_geldsetzer_uncertainty'] = np.nan\n",
    "            layer_df.at[idx, 'elastic_modulus_bergfeld_kim_geldsetzer_relative_uncertainty'] = np.nan\n",
    "# Process measured density method (without uncertainty)\n",
    "print(\"Processing measured density method...\")\n",
    "for idx, row in layer_df.iterrows():\n",
    "    density_measured = row['density_measured']\n",
    "    \n",
    "    # Handle the case where density_measured might be an array or have multiple values\n",
    "    if density_measured is not None:\n",
    "        # Convert to scalar if it's an array\n",
    "        if hasattr(density_measured, '__len__') and not isinstance(density_measured, str):\n",
    "            if len(density_measured) > 0:\n",
    "                density_measured = density_measured[0]\n",
    "            else:\n",
    "                density_measured = None\n",
    "        \n",
    "        # Check if we have a valid scalar value\n",
    "        if density_measured is not None and pd.notna(density_measured):\n",
    "            # Create ufloat with density but no uncertainty (std_dev = 0)\n",
    "            density_ufloat = ufloat(float(density_measured), 0.0)\n",
    "        \n",
    "            # Calculate elastic modulus using Bergfeld method\n",
    "            try:\n",
    "                E_modulus = elastic_modulus.calculate_elastic_modulus(method='bergfeld', density=density_ufloat)\n",
    "                \n",
    "                # Check if result is valid (not NaN)\n",
    "                if not np.isnan(E_modulus.nominal_value):\n",
    "                    results['measured']['elastic_modulus_values'].append(E_modulus)\n",
    "                    results['measured']['successful_count'] += 1\n",
    "                    \n",
    "                    # Store results back in dataframe\n",
    "                    layer_df.at[idx, 'elastic_modulus_bergfeld_measured'] = E_modulus.nominal_value\n",
    "                    layer_df.at[idx, 'elastic_modulus_bergfeld_measured_uncertainty'] = E_modulus.std_dev\n",
    "                    layer_df.at[idx, 'elastic_modulus_bergfeld_measured_relative_uncertainty'] = E_modulus.std_dev / E_modulus.nominal_value\n",
    "                else:\n",
    "                    layer_df.at[idx, 'elastic_modulus_bergfeld_measured'] = np.nan\n",
    "                    layer_df.at[idx, 'elastic_modulus_bergfeld_measured_uncertainty'] = np.nan\n",
    "                    \n",
    "            except Exception as e:\n",
    "                layer_df.at[idx, 'elastic_modulus_bergfeld_measured'] = np.nan\n",
    "                layer_df.at[idx, 'elastic_modulus_bergfeld_measured_uncertainty'] = np.nan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7591a4a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== BERGFELD ELASTIC MODULUS CALCULATION RESULTS ===\n",
      "Kim-Geldsetzer method:\n",
      "  - Total layers with kim_geldsetzer density: 235522\n",
      "  - Successful calculations: 207373 (88.05%)\n",
      "  - Average relative uncertainty: 0.80%\n",
      "\n",
      "Measured density method:\n",
      "  - Total layers with measured density: 10468\n",
      "  - Successful calculations: 6825 (65.20%)\n",
      "  - Average relative uncertainty: 0.24%\n",
      "\n",
      "Updated layer data saved to layer_df.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Print summary statistics\n",
    "print(\"\\n=== BERGFELD ELASTIC MODULUS CALCULATION RESULTS ===\")\n",
    "print(\"Kim-Geldsetzer method:\")\n",
    "print(f\"  - Total layers with kim_geldsetzer density: {layer_df['density_kim_geldsetzer'].notna().sum()}\")\n",
    "print(f\"  - Successful calculations: {results['kim_geldsetzer']['successful_count']} ({(results['kim_geldsetzer']['successful_count'] / layer_df['density_kim_geldsetzer'].notna().sum()) * 100:.2f}%)\")\n",
    "print(f\"  - Average relative uncertainty: {layer_df['elastic_modulus_bergfeld_kim_geldsetzer_relative_uncertainty'].mean():.2f}%\")\n",
    "\n",
    "print(\"\\nMeasured density method:\")\n",
    "print(f\"  - Total layers with measured density: {layer_df['density_measured'].notna().sum()}\")\n",
    "print(f\"  - Successful calculations: {results['measured']['successful_count']} ({(results['measured']['successful_count'] / layer_df['density_measured'].notna().sum()) * 100:.2f}%)\")\n",
    "print(f\"  - Average relative uncertainty: {layer_df['elastic_modulus_bergfeld_measured_relative_uncertainty'].mean():.2f}%\")\n",
    "\n",
    "# Save updated dataframe\n",
    "layer_df.to_csv('layer_df.csv', index=False)\n",
    "print(\"\\nUpdated layer data saved to layer_df.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
