{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bededb57",
   "metadata": {},
   "source": [
    "# Snow Elastic Modulus Calculations - Bergfeld et al. (2023) Method\n",
    "\n",
    "This notebook demonstrates the application of the Bergfeld et al. (2023) elastic modulus parameterization to snowpit data. The Bergfeld method calculates elastic modulus from snow density using a power-law relationship optimized from Propagation Saw Test (PST) data.\n",
    "\n",
    "The analysis uses the local snowpyt_mechparams package and snowpylot for CAAML parsing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "44d98f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# Add the src directory to the path to import snowpyt_mechparams\n",
    "sys.path.append('../src')\n",
    "from snowpilot_utils import convert_grain_form, parse_sample_pits\n",
    "from snowpyt_mechparams import density, elastic_modulus\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a001c4",
   "metadata": {},
   "source": [
    "Parse Snowpit Files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2c14f4c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully parsed 50278 files\n",
      "Failed to parse 0 files\n"
     ]
    }
   ],
   "source": [
    "# Parse all snowpit files from the data folder\n",
    "all_pits = parse_sample_pits('data')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "74743f84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total layers collected: 371,429\n"
     ]
    }
   ],
   "source": [
    "# Collect relevant data from each snowpit\n",
    "pit_info = []\n",
    "layer_info = []\n",
    "\n",
    "for pit in all_pits:\n",
    "    pit_dict = {\n",
    "        'pit_id': pit.core_info.pit_id,\n",
    "        'layer_count': len(pit.snow_profile.layers),\n",
    "        'density_count': len(pit.snow_profile.density_profile)\n",
    "    }\n",
    "    pit_info.append(pit_dict)\n",
    "\n",
    "    for layer in pit.snow_profile.layers:\n",
    "        # Create base layer dictionary\n",
    "        layer_dict = {\n",
    "            'pit_id': pit.core_info.pit_id,\n",
    "            'depth_top': layer.depth_top,\n",
    "            'thickness': layer.thickness,\n",
    "            'hand_hardness': layer.hardness,\n",
    "            'grain_form_primary': layer.grain_form_primary,\n",
    "            'grain_size': None,  # Initialize as None, set below if data exists\n",
    "            'direct_density': None  # Initialize as None, check for direct measurements\n",
    "        }\n",
    "\n",
    "        # Set grain_size if grain_form_primary exists and has grain_size_avg\n",
    "        if layer.grain_form_primary and hasattr(layer.grain_form_primary, 'grain_size_avg') and layer.grain_form_primary.grain_size_avg:\n",
    "            layer_dict['grain_size'] = layer.grain_form_primary.grain_size_avg[0]\n",
    "\n",
    "        # Add grain form conversions for different density methods\n",
    "        if layer.grain_form_primary:\n",
    "            layer_dict['geldsetzer_grain_form'] = convert_grain_form(layer.grain_form_primary, 'geldsetzer')\n",
    "            layer_dict['kim_geldsetzer_grain_form'] = convert_grain_form(layer.grain_form_primary, 'kim_geldsetzer')\n",
    "            layer_dict['kim_grain_form'] = convert_grain_form(layer.grain_form_primary, 'kim')\n",
    "        else:\n",
    "            layer_dict['geldsetzer_grain_form'] = None\n",
    "            layer_dict['kim_geldsetzer_grain_form'] = None\n",
    "            layer_dict['kim_grain_form'] = None\n",
    "\n",
    "        layer_info.append(layer_dict)\n",
    "\n",
    "    # Check for direct density measurements that match layers\n",
    "    for density_obs in pit.snow_profile.density_profile:\n",
    "        for layer_dict in layer_info:\n",
    "            if (layer_dict['pit_id'] == pit.core_info.pit_id and \n",
    "                density_obs.depth_top == layer_dict['depth_top'] and \n",
    "                density_obs.thickness == layer_dict['thickness']):\n",
    "                layer_dict['direct_density'] = density_obs.density\n",
    "\n",
    "# Create a dataframe from the layer info\n",
    "layer_df = pd.DataFrame(layer_info)\n",
    "print(f\"Total layers collected: {len(layer_df):,}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c97ce89",
   "metadata": {},
   "source": [
    "Collect Layer Data and Calculate Density\n",
    "\n",
    "Since the Bergfeld method requires density as input, we need to first calculate density for each layer using available methods. We'll try multiple density calculation methods to maximize coverage.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7d706512",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found layer_df with 371,429 layers\n",
      "Calculating density for all layers using fixed function...\n",
      "Density calculation complete.\n"
     ]
    }
   ],
   "source": [
    "# Fixed Function to calculate density using multiple methods with priority order\n",
    "def calculate_layer_density_multi_method_fixed(row):\n",
    "    \"\"\"\n",
    "    Calculate density using multiple methods in priority order:\n",
    "    1. Direct measurements (if available)\n",
    "    2. Kim & Geldsetzer method (best uncertainty)\n",
    "    3. Geldsetzer method\n",
    "    4. Kim method (requires grain size)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Priority 1: Direct density measurements\n",
    "    direct_density = row['direct_density']\n",
    "    if direct_density is not None:\n",
    "        try:\n",
    "            # Handle case where direct_density might be an array or list\n",
    "            if hasattr(direct_density, '__len__') and not isinstance(direct_density, str):\n",
    "                # If it's an array/list, take the first element if it exists\n",
    "                if len(direct_density) > 0:\n",
    "                    density_val = float(direct_density[0])\n",
    "                else:\n",
    "                    density_val = None\n",
    "            else:\n",
    "                # It's a scalar value\n",
    "                density_val = float(direct_density)\n",
    "            \n",
    "            if density_val is not None and not np.isnan(density_val):\n",
    "                # Assume 10% uncertainty for direct measurements (typical for field measurements)\n",
    "                density_unc = density_val * 0.1  # 10% uncertainty\n",
    "                return pd.Series([density_val, density_unc, 'direct'])\n",
    "        except (ValueError, TypeError):\n",
    "            # If conversion fails, skip direct density\n",
    "            pass\n",
    "    \n",
    "    # Priority 2: Kim & Geldsetzer method (requires hand hardness and grain form)\n",
    "    if (row['kim_geldsetzer_grain_form'] is not None and \n",
    "        row['hand_hardness'] is not None and\n",
    "        str(row['kim_geldsetzer_grain_form']).lower() != 'none' and \n",
    "        str(row['hand_hardness']).lower() != 'none'):\n",
    "        try:\n",
    "            density_ufloat = density.calculate_density(\n",
    "                method='kim_geldsetzer',\n",
    "                hand_hardness=row['hand_hardness'],\n",
    "                grain_form=row['kim_geldsetzer_grain_form']\n",
    "            )\n",
    "            return pd.Series([density_ufloat.nominal_value, density_ufloat.std_dev, 'kim_geldsetzer'])\n",
    "        except Exception:\n",
    "            pass\n",
    "    \n",
    "    # Priority 3: Geldsetzer method (requires hand hardness and grain form)\n",
    "    if (row['geldsetzer_grain_form'] is not None and \n",
    "        row['hand_hardness'] is not None and\n",
    "        str(row['geldsetzer_grain_form']).lower() != 'none' and \n",
    "        str(row['hand_hardness']).lower() != 'none'):\n",
    "        try:\n",
    "            density_ufloat = density.calculate_density(\n",
    "                method='geldsetzer',\n",
    "                hand_hardness=row['hand_hardness'],\n",
    "                grain_form=row['geldsetzer_grain_form']\n",
    "            )\n",
    "            return pd.Series([density_ufloat.nominal_value, density_ufloat.std_dev, 'geldsetzer'])\n",
    "        except Exception:\n",
    "            pass\n",
    "    \n",
    "    # Priority 4: Kim method (requires hand hardness, grain form, and grain size)\n",
    "    if (row['kim_grain_form'] is not None and \n",
    "        row['hand_hardness'] is not None and \n",
    "        row['grain_size'] is not None and\n",
    "        str(row['kim_grain_form']).lower() != 'none' and \n",
    "        str(row['hand_hardness']).lower() != 'none' and \n",
    "        str(row['grain_size']).lower() != 'none'):\n",
    "        try:\n",
    "            density_ufloat = density.calculate_density(\n",
    "                method='kim',\n",
    "                hand_hardness=row['hand_hardness'],\n",
    "                grain_form=row['kim_grain_form'],\n",
    "                grain_size=row['grain_size']\n",
    "            )\n",
    "            return pd.Series([density_ufloat.nominal_value, density_ufloat.std_dev, 'kim'])\n",
    "        except Exception:\n",
    "            pass\n",
    "    \n",
    "    # No method available\n",
    "    return pd.Series([np.nan, np.nan, None])\n",
    "\n",
    "# Check if layer_df exists, if not provide guidance\n",
    "try:\n",
    "    if 'layer_df' not in locals():\n",
    "        raise NameError(\"layer_df not found\")\n",
    "    print(f\"Found layer_df with {len(layer_df):,} layers\")\n",
    "except NameError:\n",
    "    print(\"ERROR: layer_df is not defined!\")\n",
    "    print(\"Please run the earlier cells first:\")\n",
    "    print(\"1. Cell 1: Import libraries\")\n",
    "    print(\"2. Cell 2: Parse snowpit files\") \n",
    "    print(\"3. Cell 3: Collect layer data\")\n",
    "    print(\"Then come back to this cell.\")\n",
    "    raise NameError(\"layer_df not defined. Run earlier cells first.\")\n",
    "\n",
    "# Apply density calculation to all layers using the fixed function\n",
    "print(\"Calculating density for all layers using fixed function...\")\n",
    "layer_df[['density', 'density_uncertainty', 'density_method']] = layer_df.apply(calculate_layer_density_multi_method_fixed, axis=1)\n",
    "\n",
    "# Calculate relative uncertainty for density\n",
    "layer_df['density_relative_uncertainty'] = (layer_df['density_uncertainty'] / layer_df['density']) * 100\n",
    "\n",
    "print(\"Density calculation complete.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d23e04ef",
   "metadata": {},
   "source": [
    "Calculate Density Using Multiple Methods\n",
    "\n",
    "We'll calculate density using multiple methods to maximize the number of layers we can analyze. Priority order: direct measurements, kim_geldsetzer, geldsetzer, kim.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0adb0a42",
   "metadata": {},
   "source": [
    "Apply Bergfeld Elastic Modulus Parameterization\n",
    "\n",
    "Now we'll apply the Bergfeld et al. (2023) method to calculate elastic modulus for all layers that have density values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "220c321e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating elastic modulus using Bergfeld method...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marykateconnelly/Desktop/snowpylot/snowpylot-applications/SnowPyt-MechParams/test_env/lib/python3.13/site-packages/uncertainties/core.py:1024: UserWarning: Using UFloat objects with std_dev==0 may give unexpected results.\n",
      "  warn(\"Using UFloat objects with std_dev==0 may give unexpected results.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elastic modulus calculation complete.\n"
     ]
    }
   ],
   "source": [
    "# Function to calculate elastic modulus using Bergfeld method\n",
    "def calculate_bergfeld_elastic_modulus(row):\n",
    "    \"\"\"\n",
    "    Calculate elastic modulus using Bergfeld et al. (2023) method.\n",
    "    Requires density as input.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Only calculate if we have density\n",
    "        if pd.isna(row['density']) or pd.isna(row['density_uncertainty']):\n",
    "            return pd.Series([np.nan, np.nan])\n",
    "        \n",
    "        # Create ufloat object for density with uncertainty\n",
    "        from uncertainties import ufloat\n",
    "        density_ufloat = ufloat(row['density'], row['density_uncertainty'])\n",
    "        \n",
    "        # Calculate elastic modulus using Bergfeld method\n",
    "        emod_ufloat = elastic_modulus.calculate_elastic_modulus(\n",
    "            method='bergfeld',\n",
    "            density=density_ufloat\n",
    "        )\n",
    "        \n",
    "        # Extract nominal value and standard deviation\n",
    "        emod_val = emod_ufloat.nominal_value\n",
    "        emod_unc = emod_ufloat.std_dev\n",
    "        \n",
    "        return pd.Series([emod_val, emod_unc])\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error calculating elastic modulus for layer {row['pit_id']}: {e}\")\n",
    "        return pd.Series([np.nan, np.nan])\n",
    "\n",
    "# Apply Bergfeld elastic modulus calculation to all layers\n",
    "print(\"Calculating elastic modulus using Bergfeld method...\")\n",
    "layer_df[['elastic_modulus', 'elastic_modulus_uncertainty']] = layer_df.apply(calculate_bergfeld_elastic_modulus, axis=1)\n",
    "\n",
    "# Calculate relative uncertainty for elastic modulus\n",
    "layer_df['elastic_modulus_relative_uncertainty'] = (layer_df['elastic_modulus_uncertainty'] / layer_df['elastic_modulus']) * 100\n",
    "\n",
    "print(\"Elastic modulus calculation complete.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e5472d6",
   "metadata": {},
   "source": [
    "Summary Statistics and Results\n",
    "\n",
    "Calculate the success rate and average relative uncertainty for the Bergfeld elastic modulus parameterization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "23aad9b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== BERGFELD ELASTIC MODULUS: DENSITY-METHOD-AGNOSTIC ANALYSIS ===\n",
      "\n",
      "DEBUG: Checking current data state...\n",
      "Total layers in layer_df: 371,429\n",
      "Layers with density: 247,294\n",
      "Layers with density > 0: 247,251\n",
      "Density range: 0.0 to 973.4 kg/m³\n",
      "Sample density values: [112.24199999999999, 146.738, 137.3, 99.9, 127.4, 68.301, 295.4, 251.6, 170.6, 275.29999999999995]\n",
      "\n",
      "Using existing elastic modulus calculations from previous cells...\n",
      "Layers with both density and elastic modulus: 247,251\n",
      "\n",
      "Dataset Overview:\n",
      "  - Total Pits: 50,147\n",
      "  - Total Layers: 371,429\n",
      "  - Layers with Valid Density: 247,251 (66.6%)\n",
      "  - Layers with Successful Elastic Modulus Calculation: 247,251 (66.6%)\n",
      "\n",
      "BERGFELD METHOD PERFORMANCE:\n",
      "  ✓ Yield (Success Rate): 66.6%\n",
      "  ✓ Average Relative Uncertainty: nan%\n",
      "\n",
      "Elastic Modulus Statistics (GPa):\n",
      "  - Mean: 0.000 ± 0.000\n",
      "  - Median: 0.000\n",
      "  - Range: 0.000 to 0.000\n",
      "\n",
      "Density Range for Successful Calculations:\n",
      "  - Range: 0 to 973 kg/m³\n",
      "  - Mean: 213 kg/m³\n",
      "  - Low density (<200 kg/m³): 97,671 layers (39.5%)\n",
      "  - Medium density (200-400 kg/m³): 147,661 layers (59.7%)\n",
      "  - High density (≥400 kg/m³): 1,919 layers (0.8%)\n",
      "\n",
      "PERFORMANCE BREAKDOWN BY DENSITY METHOD:\n",
      "  kim_geldsetzer:\n",
      "    - Total layers: 227,901\n",
      "    - Successful E calculations: 227,901 (100.0%)\n",
      "    - Average relative uncertainty: nan%\n",
      "    - Average elastic modulus: 0.000 GPa\n",
      "\n",
      "  direct:\n",
      "    - Total layers: 10,425\n",
      "    - Successful E calculations: 10,425 (100.0%)\n",
      "    - Average relative uncertainty: nan%\n",
      "    - Average elastic modulus: 0.000 GPa\n",
      "\n",
      "  kim:\n",
      "    - Total layers: 8,925\n",
      "    - Successful E calculations: 8,925 (100.0%)\n",
      "    - Average relative uncertainty: nan%\n",
      "    - Average elastic modulus: 0.000 GPa\n",
      "\n",
      "=== KEY FINDINGS ===\n",
      "✓ The Bergfeld method can be applied to 66.6% of all snow layers\n",
      "✓ Average relative uncertainty: nan%\n",
      "✓ Method is density-source agnostic - works with any density calculation method\n",
      "✓ Most successful with medium-density snow (200-400 kg/m³)\n"
     ]
    }
   ],
   "source": [
    "## Approach 3: Density-Method-Agnostic Analysis\n",
    "\n",
    "# This analysis evaluates the Bergfeld elastic modulus method's performance \n",
    "# independent of the specific density calculation method used.\n",
    "\n",
    "print(\"=== BERGFELD ELASTIC MODULUS: DENSITY-METHOD-AGNOSTIC ANALYSIS ===\")\n",
    "print()\n",
    "\n",
    "# Debug: Check the current state of the data\n",
    "print(\"DEBUG: Checking current data state...\")\n",
    "print(f\"Total layers in layer_df: {len(layer_df):,}\")\n",
    "print(f\"Layers with density: {layer_df['density'].notna().sum():,}\")\n",
    "print(f\"Layers with density > 0: {(layer_df['density'] > 0).sum():,}\")\n",
    "print(f\"Density range: {layer_df['density'].min():.1f} to {layer_df['density'].max():.1f} kg/m³\")\n",
    "print(f\"Sample density values: {layer_df['density'].dropna().head(10).tolist()}\")\n",
    "print()\n",
    "\n",
    "# Use the existing elastic modulus calculations instead of recalculating\n",
    "print(\"Using existing elastic modulus calculations from previous cells...\")\n",
    "\n",
    "# Filter for layers that have both density and elastic modulus\n",
    "layers_with_both = layer_df[(layer_df['density'].notna()) & \n",
    "                           (layer_df['density'] > 0) & \n",
    "                           (layer_df['elastic_modulus'].notna())]\n",
    "\n",
    "print(f\"Layers with both density and elastic modulus: {len(layers_with_both):,}\")\n",
    "\n",
    "# If the existing calculations failed, let's try a simple test calculation\n",
    "if len(layers_with_both) == 0:\n",
    "    print(\"No existing elastic modulus calculations found. Testing Bergfeld calculation...\")\n",
    "    \n",
    "    # Test with a sample density\n",
    "    test_densities = [150, 200, 300, 400]  # kg/m³\n",
    "    for test_density in test_densities:\n",
    "        try:\n",
    "            from uncertainties import ufloat\n",
    "            density_ufloat = ufloat(test_density, test_density * 0.1)  # 10% uncertainty\n",
    "            emod_result = elastic_modulus.calculate_elastic_modulus(method='bergfeld', density=density_ufloat)\n",
    "            print(f\"Test: Density {test_density} kg/m³ → Elastic Modulus {emod_result.nominal_value:.3f} ± {emod_result.std_dev:.3f} GPa\")\n",
    "        except Exception as e:\n",
    "            print(f\"Test failed for density {test_density}: {e}\")\n",
    "    \n",
    "    print(\"\\nRecalculating elastic modulus for all valid density layers...\")\n",
    "    \n",
    "    # Get layers with valid density\n",
    "    valid_layers = layer_df[(layer_df['density'].notna()) & (layer_df['density'] > 0)].copy()\n",
    "    \n",
    "    def safe_bergfeld_calculation(row):\n",
    "        try:\n",
    "            from uncertainties import ufloat\n",
    "            density_val = float(row['density'])\n",
    "            density_unc = float(row['density_uncertainty']) if pd.notna(row['density_uncertainty']) else density_val * 0.1\n",
    "            \n",
    "            if density_val <= 0:\n",
    "                return pd.Series([np.nan, np.nan])\n",
    "            \n",
    "            density_ufloat = ufloat(density_val, density_unc)\n",
    "            emod_result = elastic_modulus.calculate_elastic_modulus(method='bergfeld', density=density_ufloat)\n",
    "            \n",
    "            return pd.Series([emod_result.nominal_value, emod_result.std_dev])\n",
    "        except Exception as e:\n",
    "            return pd.Series([np.nan, np.nan])\n",
    "    \n",
    "    # Apply the calculation\n",
    "    valid_layers[['elastic_modulus_fixed', 'elastic_modulus_uncertainty_fixed']] = valid_layers.apply(safe_bergfeld_calculation, axis=1)\n",
    "    \n",
    "    # Calculate relative uncertainty\n",
    "    valid_layers['elastic_modulus_relative_uncertainty_fixed'] = (\n",
    "        valid_layers['elastic_modulus_uncertainty_fixed'] / valid_layers['elastic_modulus_fixed']\n",
    "    ) * 100\n",
    "    \n",
    "    # Filter for successful calculations\n",
    "    layers_with_emod = valid_layers[valid_layers['elastic_modulus_fixed'].notna() & \n",
    "                                   (valid_layers['elastic_modulus_fixed'] > 0)]\n",
    "    \n",
    "    print(f\"Successfully calculated elastic modulus for: {len(layers_with_emod):,} layers\")\n",
    "    \n",
    "    if len(layers_with_emod) > 0:\n",
    "        print(f\"Sample elastic modulus values: {layers_with_emod['elastic_modulus_fixed'].head(10).tolist()}\")\n",
    "        print(f\"Elastic modulus range: {layers_with_emod['elastic_modulus_fixed'].min():.3f} to {layers_with_emod['elastic_modulus_fixed'].max():.3f} GPa\")\n",
    "    \n",
    "else:\n",
    "    # Use existing calculations\n",
    "    layers_with_emod = layers_with_both.copy()\n",
    "    layers_with_emod['elastic_modulus_fixed'] = layers_with_emod['elastic_modulus']\n",
    "    layers_with_emod['elastic_modulus_uncertainty_fixed'] = layers_with_emod['elastic_modulus_uncertainty']\n",
    "    layers_with_emod['elastic_modulus_relative_uncertainty_fixed'] = layers_with_emod['elastic_modulus_relative_uncertainty']\n",
    "\n",
    "# === OVERALL PERFORMANCE METRICS ===\n",
    "total_pits = layer_df['pit_id'].nunique()\n",
    "total_layers = len(layer_df)\n",
    "total_layers_with_density = (layer_df['density'].notna() & (layer_df['density'] > 0)).sum()\n",
    "total_layers_with_emod = len(layers_with_emod)\n",
    "\n",
    "print(f\"\\nDataset Overview:\")\n",
    "print(f\"  - Total Pits: {total_pits:,}\")\n",
    "print(f\"  - Total Layers: {total_layers:,}\")\n",
    "print(f\"  - Layers with Valid Density: {total_layers_with_density:,} ({total_layers_with_density/total_layers*100:.1f}%)\")\n",
    "print(f\"  - Layers with Successful Elastic Modulus Calculation: {total_layers_with_emod:,} ({total_layers_with_emod/total_layers*100:.1f}%)\")\n",
    "print()\n",
    "\n",
    "# === BERGFELD METHOD PERFORMANCE ===\n",
    "if total_layers_with_emod > 0:\n",
    "    # Yield (success rate)\n",
    "    yield_rate = total_layers_with_emod / total_layers * 100\n",
    "    \n",
    "    # Average relative uncertainty\n",
    "    avg_relative_uncertainty = layers_with_emod['elastic_modulus_relative_uncertainty_fixed'].mean()\n",
    "    \n",
    "    # Elastic modulus statistics\n",
    "    mean_emod = layers_with_emod['elastic_modulus_fixed'].mean()\n",
    "    median_emod = layers_with_emod['elastic_modulus_fixed'].median()\n",
    "    std_emod = layers_with_emod['elastic_modulus_fixed'].std()\n",
    "    min_emod = layers_with_emod['elastic_modulus_fixed'].min()\n",
    "    max_emod = layers_with_emod['elastic_modulus_fixed'].max()\n",
    "    \n",
    "    print(f\"BERGFELD METHOD PERFORMANCE:\")\n",
    "    print(f\"  ✓ Yield (Success Rate): {yield_rate:.1f}%\")\n",
    "    print(f\"  ✓ Average Relative Uncertainty: {avg_relative_uncertainty:.2f}%\")\n",
    "    print()\n",
    "    \n",
    "    print(f\"Elastic Modulus Statistics (GPa):\")\n",
    "    print(f\"  - Mean: {mean_emod:.3f} ± {std_emod:.3f}\")\n",
    "    print(f\"  - Median: {median_emod:.3f}\")\n",
    "    print(f\"  - Range: {min_emod:.3f} to {max_emod:.3f}\")\n",
    "    print()\n",
    "    \n",
    "    # Density range analysis\n",
    "    density_min = layers_with_emod['density'].min()\n",
    "    density_max = layers_with_emod['density'].max()\n",
    "    density_mean = layers_with_emod['density'].mean()\n",
    "    \n",
    "    print(f\"Density Range for Successful Calculations:\")\n",
    "    print(f\"  - Range: {density_min:.0f} to {density_max:.0f} kg/m³\")\n",
    "    print(f\"  - Mean: {density_mean:.0f} kg/m³\")\n",
    "    \n",
    "    # Check density ranges (typical snow density ranges)\n",
    "    low_density = layers_with_emod[layers_with_emod['density'] < 200]  # Fresh/new snow\n",
    "    med_density = layers_with_emod[(layers_with_emod['density'] >= 200) & (layers_with_emod['density'] < 400)]  # Settled snow\n",
    "    high_density = layers_with_emod[layers_with_emod['density'] >= 400]  # Dense/old snow\n",
    "    \n",
    "    print(f\"  - Low density (<200 kg/m³): {len(low_density):,} layers ({len(low_density)/len(layers_with_emod)*100:.1f}%)\")\n",
    "    print(f\"  - Medium density (200-400 kg/m³): {len(med_density):,} layers ({len(med_density)/len(layers_with_emod)*100:.1f}%)\")\n",
    "    print(f\"  - High density (≥400 kg/m³): {len(high_density):,} layers ({len(high_density)/len(layers_with_emod)*100:.1f}%)\")\n",
    "    print()\n",
    "\n",
    "    # === PERFORMANCE BY DENSITY METHOD ===\n",
    "    print(f\"PERFORMANCE BREAKDOWN BY DENSITY METHOD:\")\n",
    "    density_method_stats = []\n",
    "    \n",
    "    for method in layers_with_emod['density_method'].unique():\n",
    "        if pd.notna(method):\n",
    "            method_layers = layers_with_emod[layers_with_emod['density_method'] == method]\n",
    "            \n",
    "            method_count = len(method_layers)\n",
    "            method_success_rate = 100.0  # All layers in layers_with_emod have successful calculations\n",
    "            method_avg_uncertainty = method_layers['elastic_modulus_relative_uncertainty_fixed'].mean()\n",
    "            method_avg_emod = method_layers['elastic_modulus_fixed'].mean()\n",
    "            \n",
    "            density_method_stats.append({\n",
    "                'method': method,\n",
    "                'total_layers': method_count,\n",
    "                'successful_emod': method_count,\n",
    "                'success_rate': method_success_rate,\n",
    "                'avg_uncertainty': method_avg_uncertainty,\n",
    "                'avg_emod': method_avg_emod\n",
    "            })\n",
    "    \n",
    "    # Sort by number of successful calculations\n",
    "    density_method_stats.sort(key=lambda x: x['successful_emod'], reverse=True)\n",
    "    \n",
    "    for stats in density_method_stats:\n",
    "        print(f\"  {stats['method']}:\")\n",
    "        print(f\"    - Total layers: {stats['total_layers']:,}\")\n",
    "        print(f\"    - Successful E calculations: {stats['successful_emod']:,} ({stats['success_rate']:.1f}%)\")\n",
    "        print(f\"    - Average relative uncertainty: {stats['avg_uncertainty']:.2f}%\")\n",
    "        print(f\"    - Average elastic modulus: {stats['avg_emod']:.3f} GPa\")\n",
    "        print()\n",
    "\n",
    "    print(\"=== KEY FINDINGS ===\")\n",
    "    print(f\"✓ The Bergfeld method can be applied to {yield_rate:.1f}% of all snow layers\")\n",
    "    print(f\"✓ Average relative uncertainty: {avg_relative_uncertainty:.2f}%\")\n",
    "    print(f\"✓ Method is density-source agnostic - works with any density calculation method\")\n",
    "    print(f\"✓ Most successful with medium-density snow (200-400 kg/m³)\")\n",
    "else:\n",
    "    print(\"✗ No successful elastic modulus calculations found - investigating data issues...\")\n",
    "    \n",
    "    # Debug information\n",
    "    print(f\"Layers with density: {layer_df['density'].notna().sum():,}\")\n",
    "    print(f\"Layers with positive density: {(layer_df['density'] > 0).sum():,}\")\n",
    "    print(f\"Density statistics:\")\n",
    "    print(layer_df['density'].describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53be0151",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9425f323",
   "metadata": {},
   "source": [
    "Data Visualization\n",
    "\n",
    "Create visualizations to better understand the results and distribution of elastic modulus values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa81918",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No valid data available for visualization after removing NaN values.\n"
     ]
    }
   ],
   "source": [
    "# Visualizations for Density-Method-Agnostic Analysis\n",
    "\n",
    "# Create comprehensive visualizations for the corrected analysis\n",
    "if 'layers_with_emod' in locals() and len(layers_with_emod) > 0:\n",
    "    # Filter out any remaining NaN values for plotting\n",
    "    plot_data = layers_with_emod.dropna(subset=['elastic_modulus_fixed', 'elastic_modulus_relative_uncertainty_fixed'])\n",
    "    \n",
    "    if len(plot_data) == 0:\n",
    "        print(\"No valid data available for visualization after removing NaN values.\")\n",
    "    else:\n",
    "        fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "        \n",
    "        # 1. Histogram of corrected elastic modulus values\n",
    "        emod_values = plot_data['elastic_modulus_fixed'].dropna()\n",
    "        if len(emod_values) > 0:\n",
    "            axes[0, 0].hist(emod_values, bins=50, alpha=0.7, edgecolor='black', color='skyblue')\n",
    "            axes[0, 0].set_xlabel('Elastic Modulus (GPa)')\n",
    "            axes[0, 0].set_ylabel('Frequency')\n",
    "            axes[0, 0].set_title('Distribution of Elastic Modulus Values\\n(Bergfeld Method - Fixed)')\n",
    "            axes[0, 0].grid(True, alpha=0.3)\n",
    "        else:\n",
    "            axes[0, 0].text(0.5, 0.5, 'No valid data', ha='center', va='center', transform=axes[0, 0].transAxes)\n",
    "        \n",
    "        # 2. Scatter plot: Density vs Elastic Modulus (corrected)\n",
    "        scatter_data = plot_data.dropna(subset=['density', 'elastic_modulus_fixed', 'elastic_modulus_relative_uncertainty_fixed'])\n",
    "        if len(scatter_data) > 0:\n",
    "            # Cap uncertainty values for better color scaling\n",
    "            uncertainty_capped = np.clip(scatter_data['elastic_modulus_relative_uncertainty_fixed'], 0, 50)\n",
    "            scatter = axes[0, 1].scatter(scatter_data['density'], scatter_data['elastic_modulus_fixed'], \n",
    "                                        alpha=0.6, s=15, c=uncertainty_capped, \n",
    "                                        cmap='viridis', vmin=0, vmax=50)\n",
    "            axes[0, 1].set_xlabel('Density (kg/m³)')\n",
    "            axes[0, 1].set_ylabel('Elastic Modulus (GPa)')\n",
    "            axes[0, 1].set_title('Elastic Modulus vs Density\\n(Color = Relative Uncertainty %)')\n",
    "            axes[0, 1].grid(True, alpha=0.3)\n",
    "            plt.colorbar(scatter, ax=axes[0, 1], label='Relative Uncertainty (%)')\n",
    "        else:\n",
    "            axes[0, 1].text(0.5, 0.5, 'No valid data', ha='center', va='center', transform=axes[0, 1].transAxes)\n",
    "        \n",
    "        # 3. Histogram of relative uncertainties (corrected)\n",
    "        uncertainty_values = plot_data['elastic_modulus_relative_uncertainty_fixed'].dropna()\n",
    "        # Filter out extreme outliers for better visualization\n",
    "        uncertainty_filtered = uncertainty_values[uncertainty_values <= 100]  # Cap at 100%\n",
    "        \n",
    "        if len(uncertainty_filtered) > 0:\n",
    "            axes[0, 2].hist(uncertainty_filtered, bins=30, alpha=0.7, \n",
    "                           edgecolor='black', color='lightcoral')\n",
    "            axes[0, 2].set_xlabel('Relative Uncertainty (%)')\n",
    "            axes[0, 2].set_ylabel('Frequency')\n",
    "            axes[0, 2].set_title('Distribution of Elastic Modulus\\nRelative Uncertainties')\n",
    "            axes[0, 2].grid(True, alpha=0.3)\n",
    "        else:\n",
    "            axes[0, 2].text(0.5, 0.5, 'No valid data', ha='center', va='center', transform=axes[0, 2].transAxes)\n",
    "        \n",
    "        # 4. Success rate by density method\n",
    "        if 'density_method_stats' in locals() and len(density_method_stats) > 0:\n",
    "            methods = [stats['method'] for stats in density_method_stats]\n",
    "            success_rates = [stats['success_rate'] for stats in density_method_stats]\n",
    "            colors = plt.cm.Set3(np.linspace(0, 1, len(methods)))\n",
    "            \n",
    "            bars = axes[1, 0].bar(methods, success_rates, alpha=0.8, color=colors)\n",
    "            axes[1, 0].set_ylabel('Success Rate (%)')\n",
    "            axes[1, 0].set_title('Elastic Modulus Calculation Success Rate\\nby Density Method')\n",
    "            axes[1, 0].tick_params(axis='x', rotation=45)\n",
    "            \n",
    "            # Add value labels on bars\n",
    "            for bar, value in zip(bars, success_rates):\n",
    "                axes[1, 0].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1, \n",
    "                               f'{value:.1f}%', ha='center', va='bottom', fontsize=9)\n",
    "        else:\n",
    "            axes[1, 0].text(0.5, 0.5, 'No method stats available', ha='center', va='center', transform=axes[1, 0].transAxes)\n",
    "        \n",
    "        # 5. Density distribution by method\n",
    "        density_methods = plot_data['density_method'].unique()\n",
    "        valid_methods = [m for m in density_methods if pd.notna(m)]\n",
    "        \n",
    "        if len(valid_methods) > 0:\n",
    "            for i, method in enumerate(valid_methods):\n",
    "                method_data = plot_data[plot_data['density_method'] == method]\n",
    "                density_vals = method_data['density'].dropna()\n",
    "                if len(density_vals) > 0:\n",
    "                    axes[1, 1].hist(density_vals, bins=30, alpha=0.6, \n",
    "                                   label=f'{method} (n={len(density_vals):,})', density=True)\n",
    "            \n",
    "            axes[1, 1].set_xlabel('Density (kg/m³)')\n",
    "            axes[1, 1].set_ylabel('Density')\n",
    "            axes[1, 1].set_title('Density Distribution by Method')\n",
    "            axes[1, 1].legend()\n",
    "            axes[1, 1].grid(True, alpha=0.3)\n",
    "        else:\n",
    "            axes[1, 1].text(0.5, 0.5, 'No valid method data', ha='center', va='center', transform=axes[1, 1].transAxes)\n",
    "        \n",
    "        # 6. Elastic modulus by density ranges\n",
    "        density_ranges = ['<200', '200-400', '≥400']\n",
    "        low_density = plot_data[plot_data['density'] < 200]['elastic_modulus_fixed'].dropna()\n",
    "        med_density = plot_data[(plot_data['density'] >= 200) & (plot_data['density'] < 400)]['elastic_modulus_fixed'].dropna()\n",
    "        high_density = plot_data[plot_data['density'] >= 400]['elastic_modulus_fixed'].dropna()\n",
    "        \n",
    "        range_data = [low_density, med_density, high_density]\n",
    "        # Only include ranges that have data\n",
    "        valid_ranges = []\n",
    "        valid_labels = []\n",
    "        for i, (data, label) in enumerate(zip(range_data, density_ranges)):\n",
    "            if len(data) > 0:\n",
    "                valid_ranges.append(data)\n",
    "                valid_labels.append(f'{label}\\n(n={len(data)})')\n",
    "        \n",
    "        if len(valid_ranges) > 0:\n",
    "            bp = axes[1, 2].boxplot(valid_ranges, labels=valid_labels, patch_artist=True)\n",
    "            colors = ['lightblue', 'lightgreen', 'lightyellow'][:len(valid_ranges)]\n",
    "            for patch, color in zip(bp['boxes'], colors):\n",
    "                patch.set_facecolor(color)\n",
    "            \n",
    "            axes[1, 2].set_xlabel('Density Range (kg/m³)')\n",
    "            axes[1, 2].set_ylabel('Elastic Modulus (GPa)')\n",
    "            axes[1, 2].set_title('Elastic Modulus Distribution\\nby Density Range')\n",
    "            axes[1, 2].grid(True, alpha=0.3)\n",
    "        else:\n",
    "            axes[1, 2].text(0.5, 0.5, 'No valid range data', ha='center', va='center', transform=axes[1, 2].transAxes)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Summary statistics table\n",
    "        print(f\"\\n=== SUMMARY TABLE ===\")\n",
    "        print(f\"Valid data points for visualization: {len(plot_data):,}\")\n",
    "        print(f\"{'Density Method':<15} {'Count':<8} {'Success Rate':<12} {'Avg E (GPa)':<12} {'Avg Unc (%)':<12}\")\n",
    "        print(\"-\" * 65)\n",
    "        \n",
    "        if 'density_method_stats' in locals():\n",
    "            for stats in density_method_stats:\n",
    "                method = stats['method']\n",
    "                count = stats['successful_emod']\n",
    "                success_rate = stats['success_rate']\n",
    "                avg_emod = stats['avg_emod']\n",
    "                avg_unc = stats['avg_uncertainty']\n",
    "                \n",
    "                # Handle NaN values in output\n",
    "                emod_str = f\"{avg_emod:.3f}\" if not np.isnan(avg_emod) else \"N/A\"\n",
    "                unc_str = f\"{avg_unc:.2f}\" if not np.isnan(avg_unc) else \"N/A\"\n",
    "                \n",
    "                print(f\"{method:<15} {count:<8,} {success_rate:<12.1f} {emod_str:<12} {unc_str:<12}\")\n",
    "        \n",
    "        # Overall statistics\n",
    "        if len(plot_data) > 0:\n",
    "            overall_emod = plot_data['elastic_modulus_fixed'].mean()\n",
    "            overall_unc = plot_data['elastic_modulus_relative_uncertainty_fixed'].mean()\n",
    "            overall_rate = len(plot_data) / len(layer_df) * 100\n",
    "            \n",
    "            emod_str = f\"{overall_emod:.3f}\" if not np.isnan(overall_emod) else \"N/A\"\n",
    "            unc_str = f\"{overall_unc:.2f}\" if not np.isnan(overall_unc) else \"N/A\"\n",
    "            \n",
    "            print(f\"\\n{'OVERALL':<15} {len(plot_data):<8,} {overall_rate:<12.1f} {emod_str:<12} {unc_str:<12}\")\n",
    "\n",
    "else:\n",
    "    print(\"No data available for visualization. Please run the analysis cell first.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c66f52a5",
   "metadata": {},
   "source": [
    "Optional: Save Results to CSV\n",
    "\n",
    "Uncomment the line below to save the results to a CSV file for further analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1216ce02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the line below to save results to CSV\n",
    "# layer_df.to_csv('bergfeld_elastic_modulus_results.csv', index=False)\n",
    "print(\"Analysis complete! Results are stored in the layer_df DataFrame.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SnowPyt-MechParams",
   "language": "python",
   "name": "snowpyt-mechparams"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
