{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro-header",
   "metadata": {},
   "source": [
    "# D11 Bending Stiffness Comparison Across Calculation Pathways\n",
    "\n",
    "This notebook compares D11 (bending stiffness) values calculated via all possible parameterization pathways for ECTP slabs in the snow pilot dataset.\n",
    "\n",
    "## Goals\n",
    "\n",
    "1. Execute all pathways for each ECTP slab\n",
    "2. Analyze data loss along different pathways\n",
    "3. Compare D11 statistics by pathway\n",
    "4. Compare D11 statistics across pathways (per slab)\n",
    "5. Identify sources of variability\n",
    "\n",
    "## Dataset\n",
    "\n",
    "- **ECTP slabs**: Slabs from Extended Column Tests with Propagation\n",
    "- **Slab definition**: Layers above the failure layer\n",
    "- **Expected slabs**: ~14,776 from ~12,347 snow pits\n",
    "\n",
    "## D11 Calculation\n",
    "\n",
    "D11 (bending stiffness) requires:\n",
    "- **Density** (ρ) for elastic modulus calculation (4 methods)\n",
    "- **Elastic modulus** (E) on all layers (4 methods)\n",
    "- **Poisson's ratio** (ν) on all layers (2 methods)\n",
    "- **Layer positions** (depth_top, thickness) - already available\n",
    "\n",
    "Number of pathways = (# density methods) × (# E methods) × (# ν methods) = 4 × 4 × 2 = **32 unique pathways**\n",
    "\n",
    "**Key insight**: Poisson's ratio (Srivastava method) uses hand hardness + grain form directly, NOT calculated density. This prevents the creation of 80 pathways that would have resulted from E and ν independently calculating density."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-1-header",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Add src to path if needed\n",
    "sys.path.insert(0, str(Path.cwd().parent / 'src'))\n",
    "\n",
    "from snowpyt_mechparams import ExecutionEngine\n",
    "from snowpyt_mechparams.graph import graph\n",
    "from snowpyt_mechparams.algorithm import find_parameterizations\n",
    "from snowpyt_mechparams.snowpilot_utils import parse_caaml_file\n",
    "from snowpyt_mechparams.data_structures import Pit\n",
    "\n",
    "# Set plotting style\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (14, 8)\n",
    "\n",
    "print(\"✓ Imports successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-2-header",
   "metadata": {},
   "source": [
    "## 2. Verify Graph Structure and Pathway Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "verify-graph",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that D11 node exists\n",
    "D11_node = graph.get_node(\"D11\")\n",
    "print(f\"D11 node: {D11_node}\")\n",
    "print(f\"D11 node type: {D11_node.type}\")\n",
    "\n",
    "# Find all pathways to D11\n",
    "all_D11_pathways = find_parameterizations(graph, D11_node)\n",
    "print(f\"\\nTotal D11 calculation pathways: {len(all_D11_pathways)}\")\n",
    "\n",
    "# Show first 5 pathways as examples\n",
    "print(\"\\nExample pathways:\")\n",
    "for i, param in enumerate(all_D11_pathways[:5], 1):\n",
    "    print(f\"\\n{i}. {param}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-3-header",
   "metadata": {},
   "source": [
    "## 3. Load ECTP Slabs from Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set data directory path\n",
    "data_dir = Path.cwd() / 'data'\n",
    "print(f\"Data directory: {data_dir}\")\n",
    "print(f\"Exists: {data_dir.exists()}\")\n",
    "\n",
    "# Get all CAAML files\n",
    "caaml_files = list(data_dir.glob('snowpits-*-caaml.xml'))\n",
    "print(f\"\\nFound {len(caaml_files):,} CAAML files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "parse-files",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse CAAML files and create Pits\n",
    "print(\"Parsing CAAML files and creating Pits...\")\n",
    "\n",
    "pits = []\n",
    "failed_files = []\n",
    "\n",
    "for filepath in tqdm(caaml_files, desc=\"Processing files\"):\n",
    "    try:\n",
    "        # Parse CAAML file to get snowpylot SnowPit\n",
    "        snow_pit = parse_caaml_file(str(filepath))\n",
    "        \n",
    "        # Create Pit object\n",
    "        pit = Pit.from_snow_pit(snow_pit)\n",
    "        pits.append(pit)\n",
    "        \n",
    "    except Exception as e:\n",
    "        failed_files.append((filepath.name, str(e)))\n",
    "\n",
    "print(f\"\\nSuccessfully parsed: {len(pits):,} pits\")\n",
    "print(f\"Failed: {len(failed_files):,} files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "create-slabs",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create slabs using ECTP failure layers\n",
    "print(\"Creating slabs from ECTP failures...\")\n",
    "\n",
    "all_slabs = []\n",
    "pits_with_ectp = 0\n",
    "\n",
    "for pit in tqdm(pits, desc=\"Creating slabs\"):\n",
    "    # Create slabs based on ECTP failures\n",
    "    slabs = pit.create_slabs(weak_layer_def=\"ECTP_failure_layer\")\n",
    "    \n",
    "    if slabs:\n",
    "        pits_with_ectp += 1\n",
    "        all_slabs.extend(slabs)\n",
    "\n",
    "print(f\"\\nTotal pits processed: {len(pits):,}\")\n",
    "print(f\"Pits with ECTP failures: {pits_with_ectp:,} ({100*pits_with_ectp/len(pits):.1f}%)\")\n",
    "print(f\"Total ECTP slabs created: {len(all_slabs):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-4-header",
   "metadata": {},
   "source": [
    "## 4. Execute All Pathways for D11\n",
    "\n",
    "This section executes all 32 pathways for each slab. The execution engine uses **dynamic programming** to cache computed values across pathways, avoiding redundant calculations.\n",
    "\n",
    "**Expected executions**: ~14,776 slabs × 32 pathways = ~473,000 pathway executions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "execute-pathways",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize execution engine\n",
    "engine = ExecutionEngine(graph)\n",
    "\n",
    "print(f\"Executing all pathways for {len(all_slabs):,} slabs...\")\n",
    "print(f\"Total pathway executions: {len(all_slabs) * len(all_D11_pathways):,}\")\n",
    "print(\"\\nNote: Dynamic programming caches computed values within each slab.\")\n",
    "print(\"This avoids redundant calculations when pathways share common sub-paths.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "execute-loop",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute all pathways for each slab\n",
    "results_data = []\n",
    "\n",
    "for slab_idx, slab in enumerate(tqdm(all_slabs, desc=\"Executing pathways\")):\n",
    "    try:\n",
    "        # Execute all pathways (uses dynamic programming internally)\n",
    "        results = engine.execute_all(\n",
    "            slab=slab,\n",
    "            target_parameter='D11',\n",
    "            include_plate_theory=True\n",
    "        )\n",
    "\n",
    "        # Record results for each pathway\n",
    "        for pathway_desc, result in results.results.items():\n",
    "            # Record even failed pathways (for data loss analysis)\n",
    "            record = {\n",
    "                'pit_id': slab.pit_id,\n",
    "                'slab_id': slab.slab_id,\n",
    "                'slab_index': slab_idx,\n",
    "                'pathway_description': pathway_desc,\n",
    "                'methods_used': str(result.methods_used),\n",
    "                'success': result.success,\n",
    "                'D11': result.slab_result.D11.nominal_value if (result.slab_result and result.slab_result.D11) else None,\n",
    "                'D11_uncertainty': result.slab_result.D11.std_dev if (result.slab_result and result.slab_result.D11) else None,\n",
    "                'num_layers': len(slab.layers),\n",
    "                'slab_thickness_cm': slab.total_thickness,\n",
    "                'slope_angle_deg': slab.angle,\n",
    "            }\n",
    "\n",
    "            # Add failure analysis data\n",
    "            if not result.success or (result.slab_result and result.slab_result.D11 is None):\n",
    "                # Determine why it failed\n",
    "                # Count layers with missing elastic_modulus or poissons_ratio\n",
    "                missing_E = sum(1 for lr in result.layer_results if lr.layer.elastic_modulus is None)\n",
    "                missing_nu = sum(1 for lr in result.layer_results if lr.layer.poissons_ratio is None)\n",
    "                missing_thickness = sum(1 for lr in result.layer_results if lr.layer.thickness is None)\n",
    "\n",
    "                record['failure_reason'] = 'incomplete_layer_params'\n",
    "                record['layers_missing_E'] = missing_E\n",
    "                record['layers_missing_nu'] = missing_nu\n",
    "                record['layers_missing_thickness'] = missing_thickness\n",
    "                record['success'] = False\n",
    "\n",
    "            results_data.append(record)\n",
    "\n",
    "    except Exception as e:\n",
    "        # Record complete failure\n",
    "        results_data.append({\n",
    "            'pit_id': slab.pit_id,\n",
    "            'slab_id': slab.slab_id,\n",
    "            'slab_index': slab_idx,\n",
    "            'pathway_description': 'EXECUTION_ERROR',\n",
    "            'success': False,\n",
    "            'failure_reason': str(e),\n",
    "        })\n",
    "\n",
    "# Create DataFrame\n",
    "df_results = pd.DataFrame(results_data)\n",
    "\n",
    "print(f\"\\nTotal pathway executions: {len(df_results):,}\")\n",
    "print(f\"Successful calculations: {df_results['success'].sum():,}\")\n",
    "print(f\"Failed calculations: {(~df_results['success']).sum():,}\")\n",
    "print(f\"Success rate: {100 * df_results['success'].mean():.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "save-raw",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save raw results\n",
    "output_file = 'D11_pathway_comparison_raw.csv'\n",
    "df_results.to_csv(output_file, index=False)\n",
    "print(f\"\\nRaw results saved to: {output_file}\")\n",
    "print(f\"File size: {Path(output_file).stat().st_size / 1024 / 1024:.1f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-5-header",
   "metadata": {},
   "source": [
    "## 5. Data Loss Analysis by Pathway\n",
    "\n",
    "Analyze which pathways have higher success rates and why others fail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pathway-success",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"DATA LOSS ANALYSIS BY PATHWAY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Group by pathway\n",
    "pathway_stats = df_results.groupby('pathway_description').agg({\n",
    "    'success': ['sum', 'count'],\n",
    "    'D11': 'count'\n",
    "}).reset_index()\n",
    "\n",
    "pathway_stats.columns = ['pathway', 'successful', 'total', 'D11_computed']\n",
    "pathway_stats['success_rate_%'] = 100 * pathway_stats['successful'] / pathway_stats['total']\n",
    "pathway_stats['failure_rate_%'] = 100 - pathway_stats['success_rate_%']\n",
    "\n",
    "# Sort by success rate\n",
    "pathway_stats_sorted = pathway_stats.sort_values('success_rate_%', ascending=False)\n",
    "\n",
    "print(\"\\nPathway Success Rates (Top 20):\")\n",
    "print(pathway_stats_sorted.head(20).to_string(index=False))\n",
    "\n",
    "print(\"\\n\\nPathway Success Rates (Bottom 20):\")\n",
    "print(pathway_stats_sorted.tail(20).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plot-success-rates",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize success rates\n",
    "fig, ax = plt.subplots(figsize=(14, 10))\n",
    "pathways_to_plot = pathway_stats_sorted.head(30)  # Top 30\n",
    "\n",
    "y_pos = np.arange(len(pathways_to_plot))\n",
    "ax.barh(y_pos, pathways_to_plot['success_rate_%'], alpha=0.7, color='steelblue')\n",
    "ax.set_yticks(y_pos)\n",
    "ax.set_yticklabels(pathways_to_plot['pathway'], fontsize=7)\n",
    "ax.set_xlabel('Success Rate (%)', fontsize=12)\n",
    "ax.set_title('D11 Calculation Success Rate by Pathway (Top 30)', fontsize=14, fontweight='bold')\n",
    "ax.grid(axis='x', alpha=0.3)\n",
    "ax.invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.savefig('D11_success_rates_by_pathway.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Figure saved: D11_success_rates_by_pathway.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "failure-reasons",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze failure reasons\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FAILURE REASON ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "failed_df = df_results[~df_results['success']]\n",
    "if len(failed_df) > 0 and 'failure_reason' in failed_df.columns:\n",
    "    failure_counts = failed_df['failure_reason'].value_counts()\n",
    "    print(\"\\nFailure Reasons:\")\n",
    "    for reason, count in failure_counts.items():\n",
    "        pct = 100 * count / len(failed_df)\n",
    "        print(f\"  {reason}: {count:,} ({pct:.1f}%)\")\n",
    "    \n",
    "    # Analyze missing layer parameters\n",
    "    if 'layers_missing_E' in failed_df.columns:\n",
    "        print(\"\\nMissing Layer Parameters (among failures):\")\n",
    "        print(f\"  Average layers missing E: {failed_df['layers_missing_E'].mean():.2f}\")\n",
    "        print(f\"  Average layers missing ν: {failed_df['layers_missing_nu'].mean():.2f}\")\n",
    "        print(f\"  Average layers missing thickness: {failed_df['layers_missing_thickness'].mean():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-6-header",
   "metadata": {},
   "source": [
    "## 6. D11 Statistics by Individual Pathway\n",
    "\n",
    "Compare D11 distributions across different calculation pathways."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pathway-stats",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"D11 STATISTICS BY PATHWAY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Filter to successful calculations only\n",
    "df_success = df_results[df_results['success'] == True].copy()\n",
    "\n",
    "print(f\"\\nSuccessful D11 calculations: {len(df_success):,}\")\n",
    "print(f\"Unique slabs with at least one successful pathway: {df_success['slab_id'].nunique():,}\")\n",
    "print(f\"Unique pathways that succeeded: {df_success['pathway_description'].nunique()}\")\n",
    "\n",
    "# Calculate statistics for each pathway\n",
    "pathway_D11_stats = df_success.groupby('pathway_description')['D11'].agg([\n",
    "    'count',\n",
    "    'mean',\n",
    "    'median',\n",
    "    'std',\n",
    "    'min',\n",
    "    'max'\n",
    "]).reset_index()\n",
    "\n",
    "pathway_D11_stats.columns = ['pathway', 'n', 'mean_D11', 'median_D11', 'std_D11', 'min_D11', 'max_D11']\n",
    "pathway_D11_stats = pathway_D11_stats.sort_values('mean_D11', ascending=False)\n",
    "\n",
    "print(\"\\nD11 Statistics by Pathway (N·mm) - Top 20:\")\n",
    "print(pathway_D11_stats.head(20).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "save-pathway-stats",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save pathway statistics\n",
    "pathway_D11_stats.to_csv('D11_statistics_by_pathway.csv', index=False)\n",
    "print(\"\\n✓ Pathway statistics saved to: D11_statistics_by_pathway.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plot-boxplot",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box plot comparison for top pathways by sample size\n",
    "fig, ax = plt.subplots(figsize=(16, 10))\n",
    "\n",
    "# Get top 20 pathways by sample size\n",
    "top_pathways = pathway_D11_stats.nlargest(20, 'n')['pathway'].tolist()\n",
    "df_top = df_success[df_success['pathway_description'].isin(top_pathways)]\n",
    "\n",
    "# Create box plot\n",
    "bp = df_top.boxplot(column='D11', by='pathway_description', ax=ax, rot=90, patch_artist=True)\n",
    "ax.set_ylabel('D11 (N·mm)', fontsize=12)\n",
    "ax.set_xlabel('Pathway', fontsize=12)\n",
    "ax.set_title('D11 Distribution by Pathway (Top 20 by Sample Size)', fontsize=14, fontweight='bold')\n",
    "plt.suptitle('')  # Remove automatic title\n",
    "plt.xticks(fontsize=8)\n",
    "plt.tight_layout()\n",
    "plt.savefig('D11_boxplot_by_pathway.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Figure saved: D11_boxplot_by_pathway.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plot-violin",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Violin plot for top pathways\n",
    "fig, ax = plt.subplots(figsize=(16, 10))\n",
    "\n",
    "# Use top 10 for cleaner visualization\n",
    "top_10_pathways = pathway_D11_stats.nlargest(10, 'n')['pathway'].tolist()\n",
    "df_top10 = df_success[df_success['pathway_description'].isin(top_10_pathways)]\n",
    "\n",
    "sns.violinplot(data=df_top10, x='pathway_description', y='D11', ax=ax, inner='box')\n",
    "ax.set_xlabel('Pathway', fontsize=12)\n",
    "ax.set_ylabel('D11 (N·mm)', fontsize=12)\n",
    "ax.set_title('D11 Distribution by Pathway (Violin Plot - Top 10)', fontsize=14, fontweight='bold')\n",
    "plt.xticks(rotation=90, fontsize=8)\n",
    "plt.tight_layout()\n",
    "plt.savefig('D11_violin_by_pathway.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Figure saved: D11_violin_by_pathway.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-7-header",
   "metadata": {},
   "source": [
    "## 7. D11 Variability Across Pathways (Per Slab)\n",
    "\n",
    "For each slab, analyze how D11 varies across different calculation pathways."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "slab-variability",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"D11 VARIABILITY ACROSS PATHWAYS (PER SLAB)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# For each slab, calculate statistics across all successful pathways\n",
    "slab_D11_variability = df_success.groupby('slab_id')['D11'].agg([\n",
    "    'count',  # Number of successful pathways\n",
    "    'mean',   # Mean D11 across pathways\n",
    "    'std',    # Std dev across pathways (variability)\n",
    "    'min',    # Min D11\n",
    "    'max',    # Max D11\n",
    "]).reset_index()\n",
    "\n",
    "slab_D11_variability.columns = ['slab_id', 'n_pathways', 'mean_D11', 'std_D11', 'min_D11', 'max_D11']\n",
    "slab_D11_variability['range_D11'] = slab_D11_variability['max_D11'] - slab_D11_variability['min_D11']\n",
    "slab_D11_variability['cv_D11'] = slab_D11_variability['std_D11'] / slab_D11_variability['mean_D11']  # Coefficient of variation\n",
    "\n",
    "# Merge with slab properties\n",
    "slab_props = df_success[['slab_id', 'num_layers', 'slab_thickness_cm', 'slope_angle_deg']].drop_duplicates()\n",
    "slab_D11_variability = slab_D11_variability.merge(slab_props, on='slab_id')\n",
    "\n",
    "print(f\"\\nSlabs with successful D11 calculations: {len(slab_D11_variability):,}\")\n",
    "print(f\"Average successful pathways per slab: {slab_D11_variability['n_pathways'].mean():.1f}\")\n",
    "\n",
    "print(\"\\nD11 Variability Statistics:\")\n",
    "print(slab_D11_variability[['mean_D11', 'std_D11', 'cv_D11', 'range_D11']].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "save-slab-stats",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save slab-level statistics\n",
    "slab_D11_variability.to_csv('D11_variability_by_slab.csv', index=False)\n",
    "print(\"\\n✓ Slab variability statistics saved to: D11_variability_by_slab.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plot-variability-dist",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram of coefficient of variation and other variability metrics\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# CV histogram\n",
    "axes[0, 0].hist(slab_D11_variability['cv_D11'].dropna(), bins=50, edgecolor='black', alpha=0.7, color='steelblue')\n",
    "axes[0, 0].set_xlabel('Coefficient of Variation', fontsize=10)\n",
    "axes[0, 0].set_ylabel('Frequency', fontsize=10)\n",
    "axes[0, 0].set_title('D11 Coefficient of Variation Across Pathways', fontsize=11, fontweight='bold')\n",
    "axes[0, 0].axvline(slab_D11_variability['cv_D11'].median(), color='red', linestyle='--', \n",
    "                   label=f'Median: {slab_D11_variability[\"cv_D11\"].median():.3f}')\n",
    "axes[0, 0].legend()\n",
    "\n",
    "# Std dev histogram\n",
    "axes[0, 1].hist(slab_D11_variability['std_D11'].dropna(), bins=50, edgecolor='black', alpha=0.7, color='coral')\n",
    "axes[0, 1].set_xlabel('Standard Deviation (N·mm)', fontsize=10)\n",
    "axes[0, 1].set_ylabel('Frequency', fontsize=10)\n",
    "axes[0, 1].set_title('D11 Standard Deviation Across Pathways', fontsize=11, fontweight='bold')\n",
    "\n",
    "# Range histogram\n",
    "axes[1, 0].hist(slab_D11_variability['range_D11'].dropna(), bins=50, edgecolor='black', alpha=0.7, color='mediumseagreen')\n",
    "axes[1, 0].set_xlabel('Range (N·mm)', fontsize=10)\n",
    "axes[1, 0].set_ylabel('Frequency', fontsize=10)\n",
    "axes[1, 0].set_title('D11 Range Across Pathways', fontsize=11, fontweight='bold')\n",
    "\n",
    "# Number of successful pathways\n",
    "axes[1, 1].hist(slab_D11_variability['n_pathways'], \n",
    "                bins=range(int(slab_D11_variability['n_pathways'].min()), \n",
    "                          int(slab_D11_variability['n_pathways'].max())+2), \n",
    "                edgecolor='black', alpha=0.7, color='mediumpurple')\n",
    "axes[1, 1].set_xlabel('Number of Successful Pathways', fontsize=10)\n",
    "axes[1, 1].set_ylabel('Frequency', fontsize=10)\n",
    "axes[1, 1].set_title('Successful Pathways per Slab', fontsize=11, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('D11_variability_distributions.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Figure saved: D11_variability_distributions.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-8-header",
   "metadata": {},
   "source": [
    "## 8. Relationship Between Variability and Slab Properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "variability-vs-properties",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"D11 VARIABILITY vs SLAB PROPERTIES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Create scatter plots\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# CV vs slab thickness\n",
    "axes[0, 0].scatter(slab_D11_variability['slab_thickness_cm'], slab_D11_variability['cv_D11'], \n",
    "                   alpha=0.3, s=10, color='steelblue')\n",
    "axes[0, 0].set_xlabel('Slab Thickness (cm)', fontsize=10)\n",
    "axes[0, 0].set_ylabel('Coefficient of Variation', fontsize=10)\n",
    "axes[0, 0].set_title('D11 Variability vs Slab Thickness', fontsize=11, fontweight='bold')\n",
    "axes[0, 0].grid(alpha=0.3)\n",
    "\n",
    "# CV vs number of layers\n",
    "axes[0, 1].scatter(slab_D11_variability['num_layers'], slab_D11_variability['cv_D11'], \n",
    "                   alpha=0.3, s=10, color='coral')\n",
    "axes[0, 1].set_xlabel('Number of Layers', fontsize=10)\n",
    "axes[0, 1].set_ylabel('Coefficient of Variation', fontsize=10)\n",
    "axes[0, 1].set_title('D11 Variability vs Number of Layers', fontsize=11, fontweight='bold')\n",
    "axes[0, 1].grid(alpha=0.3)\n",
    "\n",
    "# CV vs slope angle\n",
    "axes[1, 0].scatter(slab_D11_variability['slope_angle_deg'], slab_D11_variability['cv_D11'], \n",
    "                   alpha=0.3, s=10, color='mediumseagreen')\n",
    "axes[1, 0].set_xlabel('Slope Angle (degrees)', fontsize=10)\n",
    "axes[1, 0].set_ylabel('Coefficient of Variation', fontsize=10)\n",
    "axes[1, 0].set_title('D11 Variability vs Slope Angle', fontsize=11, fontweight='bold')\n",
    "axes[1, 0].grid(alpha=0.3)\n",
    "\n",
    "# Mean D11 vs number of successful pathways\n",
    "axes[1, 1].scatter(slab_D11_variability['n_pathways'], slab_D11_variability['mean_D11'], \n",
    "                   alpha=0.3, s=10, color='mediumpurple')\n",
    "axes[1, 1].set_xlabel('Number of Successful Pathways', fontsize=10)\n",
    "axes[1, 1].set_ylabel('Mean D11 (N·mm)', fontsize=10)\n",
    "axes[1, 1].set_title('Mean D11 vs Number of Successful Pathways', fontsize=11, fontweight='bold')\n",
    "axes[1, 1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('D11_variability_vs_properties.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Figure saved: D11_variability_vs_properties.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "correlations",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correlations\n",
    "print(\"\\nCorrelations with D11 Coefficient of Variation:\")\n",
    "\n",
    "# Remove rows with NaN in relevant columns for correlation\n",
    "corr_data = slab_D11_variability[[\n",
    "    'slab_thickness_cm', 'num_layers', 'slope_angle_deg', \n",
    "    'n_pathways', 'cv_D11'\n",
    "]].dropna()\n",
    "\n",
    "correlations = {\n",
    "    'Slab Thickness': corr_data[['slab_thickness_cm', 'cv_D11']].corr().iloc[0, 1],\n",
    "    'Number of Layers': corr_data[['num_layers', 'cv_D11']].corr().iloc[0, 1],\n",
    "    'Slope Angle': corr_data[['slope_angle_deg', 'cv_D11']].corr().iloc[0, 1],\n",
    "    'Number of Pathways': corr_data[['n_pathways', 'cv_D11']].corr().iloc[0, 1],\n",
    "}\n",
    "\n",
    "for prop, corr in correlations.items():\n",
    "    print(f\"  {prop}: {corr:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-9-header",
   "metadata": {},
   "source": [
    "## 9. Pairwise Pathway Comparison\n",
    "\n",
    "For slabs where multiple pathways succeeded, compare D11 values pairwise to see how different methods correlate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pairwise-comparison",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"PAIRWISE PATHWAY COMPARISON\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Get most common pathways\n",
    "top_n_pathways = 6\n",
    "most_common_pathways = df_success['pathway_description'].value_counts().head(top_n_pathways).index.tolist()\n",
    "\n",
    "print(f\"\\nComparing top {top_n_pathways} most common pathways:\")\n",
    "for i, pw in enumerate(most_common_pathways, 1):\n",
    "    n = df_success[df_success['pathway_description'] == pw].shape[0]\n",
    "    print(f\"{i}. {pw[:80]}... (n={n})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plot-pairwise",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pairwise scatter plots\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "comparison_idx = 0\n",
    "for i in range(len(most_common_pathways)):\n",
    "    for j in range(i+1, len(most_common_pathways)):\n",
    "        if comparison_idx >= 4:\n",
    "            break\n",
    "\n",
    "        pw1 = most_common_pathways[i]\n",
    "        pw2 = most_common_pathways[j]\n",
    "\n",
    "        # Find slabs where both succeeded\n",
    "        slabs_pw1 = set(df_success[df_success['pathway_description'] == pw1]['slab_id'])\n",
    "        slabs_pw2 = set(df_success[df_success['pathway_description'] == pw2]['slab_id'])\n",
    "        common_slabs = slabs_pw1.intersection(slabs_pw2)\n",
    "\n",
    "        if len(common_slabs) > 10:  # Only compare if sufficient overlap\n",
    "            # Get D11 values for common slabs\n",
    "            df_pw1 = df_success[(df_success['pathway_description'] == pw1) & \n",
    "                                (df_success['slab_id'].isin(common_slabs))]\n",
    "            df_pw2 = df_success[(df_success['pathway_description'] == pw2) & \n",
    "                                (df_success['slab_id'].isin(common_slabs))]\n",
    "\n",
    "            # Merge on slab_id\n",
    "            df_comparison = df_pw1[['slab_id', 'D11']].merge(\n",
    "                df_pw2[['slab_id', 'D11']],\n",
    "                on='slab_id',\n",
    "                suffixes=('_1', '_2')\n",
    "            )\n",
    "\n",
    "            # Scatter plot\n",
    "            ax = axes[comparison_idx]\n",
    "            ax.scatter(df_comparison['D11_1'], df_comparison['D11_2'], alpha=0.5, s=10)\n",
    "\n",
    "            # Add 1:1 line\n",
    "            min_val = min(df_comparison['D11_1'].min(), df_comparison['D11_2'].min())\n",
    "            max_val = max(df_comparison['D11_1'].max(), df_comparison['D11_2'].max())\n",
    "            ax.plot([min_val, max_val], [min_val, max_val], 'r--', alpha=0.5, label='1:1 line')\n",
    "\n",
    "            # Calculate correlation\n",
    "            corr = df_comparison[['D11_1', 'D11_2']].corr().iloc[0, 1]\n",
    "\n",
    "            ax.set_xlabel(f'Pathway {i+1} D11 (N·mm)', fontsize=9)\n",
    "            ax.set_ylabel(f'Pathway {j+1} D11 (N·mm)', fontsize=9)\n",
    "            ax.set_title(f'Pathways {i+1} vs {j+1} (n={len(common_slabs)}, r={corr:.3f})', fontsize=10, fontweight='bold')\n",
    "            ax.legend(fontsize=8)\n",
    "            ax.grid(alpha=0.3)\n",
    "\n",
    "            comparison_idx += 1\n",
    "\n",
    "# Remove unused subplots\n",
    "for idx in range(comparison_idx, 4):\n",
    "    fig.delaxes(axes[idx])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('D11_pairwise_pathway_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n✓ Figure saved: D11_pairwise_pathway_comparison.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-10-header",
   "metadata": {},
   "source": [
    "## 10. Summary and Conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "summary",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\n{'Total slabs analyzed:':<45} {len(all_slabs):,}\")\n",
    "print(f\"{'Total pathway executions:':<45} {len(df_results):,}\")\n",
    "print(f\"{'Successful D11 calculations:':<45} {df_success.shape[0]:,}\")\n",
    "print(f\"{'Overall success rate:':<45} {100 * df_results['success'].mean():.1f}%\")\n",
    "print(f\"{'Slabs with at least one successful pathway:':<45} {slab_D11_variability.shape[0]:,}\")\n",
    "print(f\"{'Unique pathways that succeeded:':<45} {df_success['pathway_description'].nunique()}\")\n",
    "\n",
    "print(f\"\\n{'Mean D11 (across all calculations):':<45} {df_success['D11'].mean():.1f} N·mm\")\n",
    "print(f\"{'Median D11:':<45} {df_success['D11'].median():.1f} N·mm\")\n",
    "print(f\"{'Std dev D11:':<45} {df_success['D11'].std():.1f} N·mm\")\n",
    "print(f\"{'Range D11:':<45} {df_success['D11'].min():.1f} - {df_success['D11'].max():.1f} N·mm\")\n",
    "\n",
    "print(f\"\\n{'Mean pathway variability (CV):':<45} {slab_D11_variability['cv_D11'].mean():.3f}\")\n",
    "print(f\"{'Median pathway variability (CV):':<45} {slab_D11_variability['cv_D11'].median():.3f}\")\n",
    "print(f\"{'Max pathway variability (CV):':<45} {slab_D11_variability['cv_D11'].max():.3f}\")\n",
    "\n",
    "print(f\"\\n{'Average successful pathways per slab:':<45} {slab_D11_variability['n_pathways'].mean():.1f}\")\n",
    "print(f\"{'Max successful pathways for a single slab:':<45} {slab_D11_variability['n_pathways'].max():.0f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"EXPORTED FILES\")\n",
    "print(\"=\"*80)\n",
    "print(\"CSV Files:\")\n",
    "print(\"  1. D11_pathway_comparison_raw.csv - All pathway execution results\")\n",
    "print(\"  2. D11_statistics_by_pathway.csv - Summary statistics by pathway\")\n",
    "print(\"  3. D11_variability_by_slab.csv - Variability statistics by slab\")\n",
    "print(\"\\nFigures (PNG):\")\n",
    "print(\"  4. D11_success_rates_by_pathway.png - Success rate comparison\")\n",
    "print(\"  5. D11_boxplot_by_pathway.png - D11 distributions (box plot)\")\n",
    "print(\"  6. D11_violin_by_pathway.png - D11 distributions (violin plot)\")\n",
    "print(\"  7. D11_variability_distributions.png - CV, std, range histograms\")\n",
    "print(\"  8. D11_variability_vs_properties.png - Variability vs slab properties\")\n",
    "print(\"  9. D11_pairwise_pathway_comparison.png - Pairwise pathway correlations\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"KEY FINDINGS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Find pathway with highest success rate\n",
    "best_pathway = pathway_stats_sorted.iloc[0]\n",
    "print(f\"\\n1. Highest Success Rate Pathway:\")\n",
    "print(f\"   {best_pathway['pathway'][:80]}...\")\n",
    "print(f\"   Success rate: {best_pathway['success_rate_%']:.1f}%\")\n",
    "\n",
    "# Find pathway with most similar results (lowest CV)\n",
    "if len(slab_D11_variability) > 0:\n",
    "    print(f\"\\n2. Pathway Variability:\")\n",
    "    print(f\"   Mean CV across slabs: {slab_D11_variability['cv_D11'].mean():.3f}\")\n",
    "    print(f\"   This suggests pathway choice affects D11 by ~{100*slab_D11_variability['cv_D11'].mean():.1f}% on average\")\n",
    "\n",
    "# Correlation insights\n",
    "print(f\"\\n3. Property Correlations:\")\n",
    "strongest_corr = max(correlations.items(), key=lambda x: abs(x[1]))\n",
    "print(f\"   Strongest correlation with CV: {strongest_corr[0]} (r={strongest_corr[1]:.3f})\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
